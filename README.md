# isugifNF-GATK 
## (A descri√ß√£o, instru√ß√µes e adapta√ß√µes do manual original de uso deste pipeline ainda est√£o em produ√ß√£o)

Para fazer a chamada de variantes de SVN, √© utilizado o pipeline em [Nextflow](https://www.nextflow.io/) isugifNF/GATK. Este pip[eline automatiza o uso do Genome Analysis Toolkit (GATK), modificado para seguir a melhores pr√°ticas descritas no Bioinformatic Workbook: GATK Best Practices Workflow for DNA-Seq. Este pipeline estende a funcionalidade do GATK, que originalmente √© focado em dados de DNA-Seq, para permitir a detec√ß√£o de variantes tamb√©m a partir de dados de RNA-Seq e de sequenciamento de leituras longas. Ele fornece uma solu√ß√£o abrangente para diferentes plataformas de sequenciamento, ampliando as capacidades de an√°lise de variantes.

## Instala√ß√£o

Voc√™ precisar√° de uma vers√£o funcional do Nextflow. Veja [aqui](https://www.nextflow.io/docs/latest/getstarted.html#requirements)Ôøºcomo instalar o Nextflow. M√≥dulos do Nextflow est√£o dispon√≠veis em alguns ambientes de computa√ß√£o HPC. Todo processo de download das ferramentas √© automatizado pelo pipeline via Nextflow e Singularity.

<details><summary>Modulos de clusters HPC</summary>

```
# === Nova
module load gcc/7.3.0-xegsmw4 nextflow
module load singularity
NEXTFLOW=nextflow

# === Condo
module load gcc/7.3.0-xegsmw4 nextflow
module load singularity
NEXTFLOW=nextflow

# === Ceres
module load nextflow
# singularity already available, no need for module
NEXTFLOW=nextflow

# === Atlas (will need a local install of nextflow and will need the --account "projectname" flag)
module load singularity
NEXTFLOW=/project/isu_gif_vrsc/programs/nextflow
```

</details>

Uma vez que o Nextflow esteja instalado, o comando abaixo pode ser usado para ver o menu do isugifNF/GATK

```
nextflow run isugifNF/GATK --help
```

<details><summary>See help statement</summary>

```
N E X T F L O W  ~  version 20.10.0
Launching `isugifNF/GATK` [big_kare] - revision: ca139b5b5f
   Usage:
   The typical command for running the pipeline are as follows:

   DNAseq:
     nextflow run main.nf --genome GENOME.fasta --reads "*_{R1,R2}.fastq.gz" --seq "dna" -profile singularity
     nextflow run main.nf --genome GENOME.fasta --reads_file READ_PATHS.txt --seq "dna" -profile singularity

   RNAseq:
     nextflow run main.nf --genome GENOME.fasta --gtf "genes.gtf" --reads "*_{R1,R2}.fastq.gz" --seq "rna" -profile singularity
  
   PacBio Long Reads:
     nextflow run main.nf --genome GENOME.fasta --long_reads "*.fastq.gz" --seq "longread" -profile singularity

   Mandatory arguments:
    --seq                   Specify input sequence type as 'dna', 'rna', or 'longread' [default:'dna'].
    --genome                Reference genome fasta file, against which reads will be mapped to find Variant sites

   Read input arguments:
    --reads                 Paired-end reads in fastq.gz format, will need to specify glob (e.g. "*_{R1,R2}.fastq.gz")
    --reads_file            Text file (tab delimited) with three columns [readname left_fastq.gz right_fastq.gz]. Will need full path for files.
    --long_reads            Long read file in fastq.gz format, will need to specify glob (e.g. "*.fastq.gz")

   Optional analysis arguments:
    --invariant             Output invariant sites [default:false]
    --gtf                   Gene Transfer Format file, only required for RNAseq input [default:false]
    --window                Window size passed to bedtools for parallel GATK Haplotype calls [default:100000]

   Optional configuration arguments:
    -profile                Configuration profile to use. Can use multiple (comma separated)
                            Available: local, slurm, singularity, docker [default:local]
    --container_img         Container image used for singularity and docker [default:'docker://ghcr.io/aseetharam/gatk:master']
    
   GATK:
    --gatk_app              Link to gatk executable [default: 'gatk']
    --java_options          Java options for gatk [default:'-Xmx80g -XX:+UseParallelGC -Djava.io.tmpdir=$TMPDIR']
    --gatk_cluster_options  GATK cluster options [default:'false']
    
   Aligners:
    --bwamem2_app           Link to bwamem2 executable [default: 'bwa-mem2']
    --star_app              Link to star executable [default: 'STAR']
    --star_index_params     Parameters for star index [default: ' ']
    --star_index_params     Parameters to pass to STAR index [default:'']
    --star_index_file       Optional: speedup by providing a prebuilt STAR indexed genome [default: 'false']
    --pbmm2_app             Link to pbmm2 executable [default: 'pbmm2']

   Other:
    --samtools_app          Link to samtools executable [default: 'samtools']
    --bedtools_app          Link to bedtools executable [default: 'bedtools']
    --datamash_app          Link to datamash executable [default: 'datamash']
    --vcftools_app          Link to vcftools executable [default: 'vcftools']

   Optional other arguments:
    --outdir                Output directory [default:'./GATK_Results']
    --threads               Threads per process [default:4 for local, 16 for slurm] 
    --queueSize             Maximum jobs to submit to slurm [default:40]
    --account               HPC account name for slurm sbatch, atlas and ceres requires this
    --help                  Print this help message

NOTE: Genome name should not contain any periods before the ".fasta"
```

</details>

### Container Singularity

As ferramentas necess√°rias para o workflow est√£o inclu√≠das no container [aseetharam/gatk:latest](https://github.com/aseetharam/gatk)Ôøº e devem ser baixadas automaticamente pelo Nextflow. (Voc√™ s√≥ precisar√° executar singularity pull se a conex√£o com o site estiver inst√°vel.)

#### Para baixar a imagem do container Singularity

```
singularity pull --name gatk.sif shub://aseetharam/gatk:latest
```

#### No Nextflow use a flag `-with-singularity` para usar a imagem baixada.

```
nextflow run isugifNF/GATK \
  --genome "test-data/ref/b73_chr1_150000001-151000000.fasta" \
  --reads "test-data/fastq/*_{R1,R2}.fastq.gz" \
  -profile slurm \
  -with-singularity gatk.sif
```

</details>

### Dataset de teste

Um conjunto de dados simples para teste da ferramenta est√° dispon√≠vel no [ISU Box](https://iastate.app.box.com/v/gatk-test-data)Ôøº. Esse conjunto cont√©m um genoma pequeno (uma por√ß√£o do cromossomo 1, B73v5) e leituras curtas de Illumina para 26 linhagens NAM (incluindo B73) e para a linhagem B73Ab10 (total de 27 linhagens).

Apenas as leituras que mapeiam para a regi√£o do genoma v5 est√£o inclu√≠das, para que o teste possa ser executado rapidamente.

H√° exemplos com m√∫ltiplos arquivos pertencentes √† mesma linhagem NAM, assim como exemplos com um √∫nico arquivo por linhagem NAM, para garantir que ambas as condi√ß√µes funcionem corretamente.

O arquivo VCF final deve conter exatamente 27 indiv√≠duos (linhagens).

Para baixar o dataset de teste, use os seguintes comandos:
```
wget https://iastate.box.com/shared/static/wt85l6s4nw4kycm2bo0gpgjq752osatu.gz
tar -xf wt85l6s4nw4kycm2bo0gpgjq752osatu.gz

ls -1 test-data/
#> fastq          # <= Pasta com a reads (paired)
#> read-group.txt
#> ref            # <= Para com o genoma de refer√™ncia
```

## Running the Pipeline

This pipeline can process DNAseq, RNAseq and PacBio long read data, which require different arguments and different input files. Please jump to the section based off of your input below.

### GATK variant calling for DNAseq data

Because this pipeline was initially developed to process DNAseq data, we have provided a test DNAseq dataset. You can fetch the pipeline and the test-data folder.

```
# Fetch pipeline
nextflow run isugifNF/GATK --help

# Fetch the test-data folder from ISU box
wget https://iastate.box.com/shared/static/wt85l6s4nw4kycm2bo0gpgjq752osatu.gz
tar -xf wt85l6s4nw4kycm2bo0gpgjq752osatu.gz
```

The general format of a run with the pipeline is to provide a genome file (`--genome`) and Illumina Paired-End Reads files (`--reads` or `--reads_file`).

```
nextflow run isugifNF/GATK \
  --genome test-data/ref/b73_chr1_150000001-151000000.fasta \
  --reads "test-data/fastq/*_{R1,R2}.fastq.gz" \
  -profile slurm,singularity \
  -resume
```

or

```
nextflow run isugifNF/GATK \
  --genome test-data/ref/b73_chr1_150000001-151000000.fasta \
  --reads_file read-path.txt \
  -profile slurm,singularity \
  -resume
```

If you are on a HPC (Nova/Condo/Ceres/Atlas), it is highly recommend to use the `submit_nf.slurm` script. The `# === Load Modules` section will need to be modified to get nextflow and singulariy running.

<details><summary>See Module Changes</summary>

```
# === Nova
module load gcc/7.3.0-xegsmw4 nextflow
module load singularity
NEXTFLOW=nextflow

# === Condo
module load gcc/7.3.0-xegsmw4 nextflow
module load singularity
NEXTFLOW=nextflow

# === Ceres
module load nextflow
# singularity already available, no need for module
NEXTFLOW=nextflow

# === Atlas
module load singularity
NEXTFLOW=/project/isu_gif_vrsc/programs/nextflow
```

</details>

### Using the --reads_file

Instead of using a pattern to specify paired reads (`"test-data/fastq/*_{R1,R2}.fastq.gz"`), we can use a tab-delimited textfile to specify the path to left and right files. The textfile should contain three columns: readname, left read path, right read path.

In our case, for the `test-data` run the following one-liner to generate a `read-path.txt`.

```
for f in test-data/fastq/*_R1.fastq.gz; do echo -e "$(basename $f |cut -f 1 -d "_")\t$(realpath $f)\t$(realpath $f | sed 's/_R1.fastq.gz/_R2.fastq.gz/g')"; done > read-path.txt
```

<details><summary>See example <b>read-path.txt</b></summary>

```
BioSample01	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample01_R1.fastq.gz	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample01_R2.fastq.gz
BioSample02	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample02_R1.fastq.gz	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample02_R2.fastq.gz
BioSample03	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample03_R1.fastq.gz	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample03_R2.fastq.gz
BioSample04	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample04_R1.fastq.gz	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample04_R2.fastq.gz
BioSample05	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample05_R1.fastq.gz	/Users/jenchang/Maize_WGS_Build/test-data/fastq/BioSample05_R2.fastq.gz
```

</details>

#### DNAseq final output

The final output will be in a `results` folder. SNPs will be in the VCF file, probably the file with the longest name (e.g. `first-round_merged_snps-only_snp-only.pass-only.vcf`).

```
results/
  |_ 01_MarkAdapters/            #<= folders contain intermediate files
  |_ 02_MapReads/
  |_ 03_PrepGATK/
  |_ 04_GATK/
  |_ 05_FilterSNPs/
  |  |_ first-round_merged_snps-only_sorted_snp-only.pass-only.vcf     #<= final SNP file
  |
  |_ report.html
  |_ timeline.html               # <= runtime information for all processes

```
## O arquivo de configura√ß√£o do Nextflow nf_local.config
Esta configura√ß√£o otimiza o pipeline isugifNF/GATK para execu√ß√£o em ambientes onde o armazenamento compartilhado (NFS) pode ser inst√°vel ou lento durante opera√ß√µes intensivas do Picard e GATK. Abaixo seguem algumas observa√ß√µes e explica√ß√µes sobre o arquivo nf_local.config.

#### 1. Observabilidade e Rastreamento
As se√ß√µes iniciais habilitam a gera√ß√£o de relat√≥rios detalhados ap√≥s a execu√ß√£o:

Report/Timeline: Gera arquivos HTML com o tempo de execu√ß√£o e uso de recursos por processo.

Trace: Fornece uma tabela detalhada (status, hash, mem√≥ria real usada) de cada task.

#### 2. Gest√£o de Arquivos Tempor√°rios (Local TMP)
Esta √© a parte mais cr√≠tica do script. Processos baseados em Java (Picard/GATK) utilizam o SortingCollection, que despeja arquivos imensos no diret√≥rio tempor√°rio quando a mem√≥ria RAM n√£o √© suficiente para ordenar os dados.

Estrat√©gia: Foi definida a vari√°vel LOCAL_TMP_BASE apontando para o /tmp local do n√≥ de computa√ß√£o (disco r√≠gido f√≠sico da m√°quina, n√£o a rede).

Objetivo: Evitar erros de "Disk quota exceeded" ou "I/O Error" comuns quando o NFS tenta lidar com milhares de pequenos arquivos tempor√°rios.

#### 3. Configura√ß√µes de Processo (Defaults vs. Espec√≠ficos)
O arquivo divide os processos em duas categorias principais:

A. I/O-Bound (Limitados por Disco)
Processos como FastqToSam, MergeBamAlignment, MarkDuplicates e SortAndFixTags.

maxForks = 1: For√ßa a execu√ß√£o de apenas uma amostra por vez para esses processos. Isso evita que m√∫ltiplas tarefas disputem a largura de banda do disco simultaneamente, o que causaria lentid√£o geral.

beforeScript: Cria e limpa manualmente pastas no /tmp local antes de iniciar o processo, garantindo que o Singularity/Apptainer e o Java usem esse espa√ßo r√°pido.

Gest√£o de Heap Java (-Xmx): O script define o uso de mem√≥ria Java de forma conservadora (geralmente menor que a mem√≥ria total do container) para deixar margem para o sistema operacional e evitar o encerramento do processo pelo gerenciador de mem√≥ria (OOM Killer).

B. CPU-Bound (Limitados por Processamento)
Processos como bwamem2 e HaplotypeCaller.

maxForks = 2: Permite um pouco mais de paralelismo, j√° que o gargalo aqui √© o c√°lculo matem√°tico e n√£o apenas a escrita em disco.

Recursos Elevados: Aloca√ß√£o de at√© 16 CPUs e 96GB de RAM para acelerar o alinhamento e a chamada de variantes.

#### 4. Controle do Executor
queueSize = 50: Limita o Nextflow a submeter no m√°ximo 50 tarefas totais para a fila do cluster ao mesmo tempo, mantendo o controle sobre a carga total no servidor.

```
report   { enabled = true; overwrite = true }
timeline { enabled = true; overwrite = true }
trace    { enabled = true }

// =====================================================
// TMP local (somente para processos Picard ‚Äúsens√≠veis‚Äù)
// - Evita NFS flakey no SortingCollection.*.tmp
// - TMP fixo por processo (sem task.hash)
// =====================================================
def LOCAL_TMP_BASE = "/tmp/${System.getenv('USER') ?: 'user'}/isugif_tmp"

// -----------------------------------------------------
// Defaults (baixos) ‚Äî o pipeline sobe nos processos pesados
// -----------------------------------------------------
process {
  cpus   = 2
  memory = 16.GB
  time   = '48h'

  // Ajuda a n√£o entupir o storage com work dirs antigos
  scratch = false
}

// -----------------------------------------------------
// Java default conservador
// (os processos I/O-bound v√£o sobrescrever)
// -----------------------------------------------------
params {
  java_options = "-Xmx16g -XX:+UseParallelGC -Djava.io.tmpdir=${System.getenv('TMPDIR')}"
}

// ===============================
// I/O-bound (serializar mais)
// ===============================
//
// Aqui √© onde seu erro acontece.
// Com muitos genomas, o gargalo √© disco/tempor√°rios, n√£o CPU/RAM.
//
process {

  // 1) PRINCIPAL CULPADO: FastqToSam
  withName: 'DNA_VARIANT_CALLING:FastqToSam' {
    cpus     = 2
    memory   = 48.GB
    time     = '48h'
    maxForks = 1

    // reduzir heap -> reduz spill / temp e volume de escrita
    ext.java_opts = "-Xmx16g -XX:+UseParallelGC -Djava.io.tmpdir=${System.getenv('TMPDIR')}"
  }

  // 2) MergeBamAlignment: usa SortingCollection -> precisa TMP local
  withName: 'DNA_VARIANT_CALLING:MergeBamAlignment_DNA' {
    cpus     = 3
    memory   = 64.GB
    time     = '72h'
    maxForks = 1

    // FOR√áA TMP LOCAL (n√£o-NFS) dentro do task
    beforeScript = """
      export TMPDIR="${LOCAL_TMP_BASE}/MergeBamAlignment_DNA"
      export SINGULARITY_TMPDIR="\$TMPDIR"
      export APPTAINER_TMPDIR="\$TMPDIR"
      mkdir -p "\$TMPDIR" && chmod 700 "\$TMPDIR"
    """

    // garante java.io.tmpdir = TMPDIR local
    ext.java_opts = '-Xmx24g -XX:+UseParallelGC -Djava.io.tmpdir=$TMPDIR'
  }

  // SortAndFixTags tamb√©m pode usar temp pesado (Picard-ish)
  withName: 'DNA_VARIANT_CALLING:SortAndFixTags_DNA' {
    cpus     = 3
    memory   = 64.GB
    time     = '72h'
    maxForks = 1

    beforeScript = """
      export TMPDIR="${LOCAL_TMP_BASE}/SortAndFixTags_DNA"
      export SINGULARITY_TMPDIR="\$TMPDIR"
      export APPTAINER_TMPDIR="\$TMPDIR"
      mkdir -p "\$TMPDIR" && chmod 700 "\$TMPDIR"
    """

    ext.java_opts = '-Xmx24g -XX:+UseParallelGC -Djava.io.tmpdir=$TMPDIR'
  }

  // MarkDuplicates costuma gerar MUITO temp e I/O (SortingCollection)
  withName: 'DNA_VARIANT_CALLING:MarkDuplicates_DNA' {
    cpus     = 4
    memory   = 96.GB
    time     = '96h'
    maxForks = 1

    beforeScript = """
      export TMPDIR="${LOCAL_TMP_BASE}/MarkDuplicates_DNA"
      export SINGULARITY_TMPDIR="\$TMPDIR"
      export APPTAINER_TMPDIR="\$TMPDIR"
      mkdir -p "\$TMPDIR" && chmod 700 "\$TMPDIR"
    """

    ext.java_opts = '-Xmx32g -XX:+UseParallelGC -Djava.io.tmpdir=$TMPDIR'
  }

  // Se existir e for Java/GATK, tamb√©m √© I/O pesado
  withName: 'DNA_VARIANT_CALLING:SamToFastq_DNA' {
    cpus     = 2
    memory   = 32.GB
    time     = '48h'
    maxForks = 1
  }

  withName: 'DNA_VARIANT_CALLING:MarkIlluminaAdapters' {
    cpus     = 2
    memory   = 32.GB
    time     = '48h'
    maxForks = 1
  }
}

// ===============================
// CPU-bound (limitar para n√£o ‚Äúderreter‚Äù o disco)
// ===============================
process {

  withName: 'DNA_VARIANT_CALLING:bwamem2_mem' {
    cpus     = 16
    memory   = 96.GB
    time     = '72h'
    maxForks = 2
  }

  withName: 'DNA_VARIANT_CALLING:gatk_HaplotypeCaller_DNA' {
    cpus     = 12
    memory   = 96.GB
    time     = '96h'
    maxForks = 2
    ext.java_opts = "-Xmx48g -XX:+UseParallelGC -Djava.io.tmpdir=${System.getenv('TMPDIR')}"
  }
}

// ===============================
// Seguran√ßa extra: limite global de tasks concorrentes
// ===============================
executor {
  queueSize = 50
}
```
## Guia de Manuten√ß√£o e Limpeza de Storage - Oncogensus

Este documento descreve as pol√≠ticas de reten√ß√£o de dados e limpeza para execu√ß√µes do pipeline `isugifNF/GATK` no cluster. O objetivo √© evitar o esgotamento do storage no `/storage3` sem comprometer a performance de futuras execu√ß√µes.

---

### üìä Vis√£o Geral dos Diret√≥rios

| Diret√≥rio | Fun√ß√£o | Reten√ß√£o Recomendada |
| :--- | :--- | :--- |
| `singularity_cache/` | Cache das imagens `.sif` (containers). | **Permanente** (N√£o apagar) |
| `.nextflow_home/` | Plugins, assets e hist√≥rico do Nextflow. | **Permanente** (N√£o apagar) |
| `isugifNF/` | C√≥digo-fonte do pipeline clonado. | **Permanente** |
| `nf_work_isugif/` | Arquivos intermedi√°rios de cada processo. | **Tempor√°ria** (Apagar ap√≥s valida√ß√£o) |
| `tmp_isugif/` | Swap de I/O, cache de extra√ß√£o e Java TMP. | **Lixo** (Apagar ap√≥s cada Job) |

---

### üßπ Protocolos de Limpeza

### 1. Limpeza de Tempor√°rios (Imediata)
O diret√≥rio definido em `$NXF_TEMP` e `$TMPDIR` acumula res√≠duos de escrita do Picard/GATK e extra√ß√µes do Apptainer/Singularity que podem n√£o ser limpos automaticamente se o job sofrer interrup√ß√µes.

**Comando:**
```bash
rm -rf /storage3/jpitta/oncogensus/tmp_isugif/*
```
### 2. Gerenciamento do Work Directory (-work-dir)
O diret√≥rio nf_work_isugif/ √© o que mais consome espa√ßo, pois armazena BAMS, FastQs e VCFs intermedi√°rios de cada etapa do GATK.

Durante o projeto: Mantenha os arquivos para permitir o uso da flag -resume.

P√≥s-conclus√£o: Ap√≥s mover os resultados finais para uma pasta de entrega/backup, limpe o diret√≥rio de trabalho.

Comando manual:

TESTE


